{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ef351e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "import networkx as nx\n",
    "import os\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "from IPython.display import Javascript\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv,SAGEConv\n",
    "from torch_geometric.nn import global_mean_pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03a681e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patients = set(['F117', 'F130', 'F128', 'F133', 'F135', 'F138', 'F139', 'F136',\n",
    "                 'F131', 'F344', 'F504', 'F510', 'M512', 'F341', 'F337', 'F324',\n",
    "                 'F308', 'F317'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30316aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unq_set = set()\n",
    "# for elem in os.listdir('clean_wcoh/kz_clean/health/'):\n",
    "#     if 'log' in elem:\n",
    "#         continue\n",
    "#     name = elem.split('_')[1]\n",
    "#     if name in test_patients:\n",
    "#         if name not in unq_set:\n",
    "#             unq_set.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "93b2046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "elecs = ['Fp1', 'Fp2', 'Fpz', 'F3', 'F4', 'Fz', 'C3', 'C4',\n",
    "         'Cz', 'P3', 'P4', 'Pz', '01', '02', '0z', 'F7', \n",
    "         'F8', 'T3', 'T4','T5', 'T6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "edae7069",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNDataset(InMemoryDataset):\n",
    "    \n",
    "    def __init__(self, root, data_dict, idx, feature_names, allow_loops = True, weighted = True, threshold = 0.6,\n",
    "                 transform = None, pre_transform = None, pre_filter = None):\n",
    "        self.data = np.load(data_dict, allow_pickle = True).item()\n",
    "        self.stage = idx # idx 0 - train, idx 1 - test\n",
    "        self.feature_names = feature_names\n",
    "        self.allow_loops = allow_loops\n",
    "        self.weighted = weighted\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[self.stage])\n",
    "        \n",
    "    def vectorize_adj_mat_coo(self, matrix, allow_loops = True):\n",
    "        source_nodes = []\n",
    "        target_nodes = []\n",
    "        if allow_loops:\n",
    "            for i in range(matrix.shape[0]):\n",
    "                for j in range(i, matrix.shape[1]):\n",
    "                    source_nodes.append(i)\n",
    "                    target_nodes.append(j)\n",
    "        else:\n",
    "            for i in range(matrix.shape[0]):\n",
    "                for j in range(i + 1, matrix.shape[1]):\n",
    "                    source_nodes.append(i)\n",
    "                    target_nodes.append(j)\n",
    "        return source_nodes, target_nodes\n",
    "    \n",
    "    def vectorize_adj_mat_weights(self, matrix, allow_loops = True, weighted = True, threshold = 0.5):\n",
    "        edge_weights = []\n",
    "        if weighted:\n",
    "            if allow_loops:\n",
    "                for i in range(matrix.shape[0]):\n",
    "                    for j in range(i, matrix.shape[1]):\n",
    "                        edge_weights.append(matrix[i][j])\n",
    "            else:\n",
    "                for i in range(matrix.shape[0]):\n",
    "                    for j in range(i + 1, matrix.shape[1]):\n",
    "                        edge_weights.append(matrix[i][j])\n",
    "        else:\n",
    "            threshold = np.min(np.max(matrix, axis = 1))\n",
    "            mask = np.array((matrix > threshold), dtype = np.uint8)\n",
    "            if allow_loops:\n",
    "                for i in range(mask.shape[0]):\n",
    "                    for j in range(i, mask.shape[1]):\n",
    "                        edge_weights.append(mask[i][j])\n",
    "            else:\n",
    "                for i in range(mask.shape[0]):\n",
    "                    for j in range(i + 1, mask.shape[1]):\n",
    "                        edge_weights.append(mask[i][j])\n",
    "        return edge_weights\n",
    "\n",
    "    def upload_data(self, patch_name):\n",
    "        '''\n",
    "        input:\n",
    "            path_to_data: path to precomputed node representations\n",
    "            path_to_adj_matr: path to precomputed adj matrices\n",
    "            \n",
    "        returns:\n",
    "            Pygeometric Data object (see PyG docs)\n",
    "        '''\n",
    "        X, target, adj_matrix = self.data[patch_name] # triplet in format [X, target, A]\n",
    "        edge_index = np.array(self.vectorize_adj_mat_coo(adj_matrix, \n",
    "                                                         allow_loops = self.allow_loops))\n",
    "        edge_features = self.vectorize_adj_mat_weights(adj_matrix, \n",
    "                                                       allow_loops = self.allow_loops,\n",
    "                                                       weighted = self.weighted, \n",
    "                                                       threshold = self.threshold)\n",
    "        return Data(x = torch.tensor(X), \n",
    "                    edge_index = torch.tensor(edge_index),\n",
    "                    edge_attrs = edge_features, \n",
    "                    y = torch.tensor([target]))  \n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'gnn_dataset_train_{self.feature_names}.pt',\n",
    "                f'gnn_dataset_test_{self.feature_names}.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "        \n",
    "    def process(self):\n",
    "        data_list = []\n",
    "        for elem in self.data.keys():\n",
    "            data_list.append(self.upload_data(elem))\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[self.stage])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff3374db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GNNDataset('./', 'train_full_data.npy', 0, 'all_features') # idx = 0 - train\n",
    "test_dataset = GNNDataset('./', 'test_full_data.npy', 1, 'all_features') # idx = 1 - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "332da6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GNNDataset('./', 'gnn_prepared_data/power_and_entropy_gnn_train.npy', 0, 'all_features',  weighted = False) # idx = 0 - train\n",
    "test_dataset = GNNDataset('./', 'gnn_prepared_data/power_and_entropy_gnn_test.npy', 1, 'all_features', weighted = False) # idx = 1 - train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1ea08844",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# for step, data in enumerate(train_loader):\n",
    "#     print(f'Step {step + 1}:')\n",
    "#     print('=======')\n",
    "#     print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "#     print(data)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2d2043a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = SAGEConv(train_dataset.num_node_features, hidden_channels)\n",
    "        self.batchnorm = torch.nn.BatchNorm1d(hidden_channels) #Vovan added\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, train_dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "#         x = self.batchnorm(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "#         x = self.batchnorm(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        #added\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x ,edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        #x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cc8db4",
   "metadata": {},
   "source": [
    "1) adj(2) + loops(2) + weighted(2) + data(3) = 2*2*2*3 = 12 exp\n",
    "2) batch size, num_layers, num_epoches, lr, scheduler\n",
    "3)\n",
    "\n",
    "object : [X, target, A]\n",
    "X - only use local info about the node\n",
    "1) acc entropy <\n",
    "2) acc power <\n",
    "3) acc power + entropy < gnn(power + entropy + adj matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8967d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GCN(hidden_channels = 128)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001, weight_decay = 0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1172b597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): SAGEConv(8, 128, aggr=mean)\n",
       "  (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): SAGEConv(128, 128, aggr=mean)\n",
       "  (conv3): SAGEConv(128, 128, aggr=mean)\n",
       "  (conv4): SAGEConv(128, 128, aggr=mean)\n",
       "  (lin): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "92732ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x.type(dtype=torch.float), data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x.type(dtype=torch.float), data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "16b718a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.4990, Test Acc: 0.5012\n",
      "Epoch: 002, Train Acc: 0.4990, Test Acc: 0.5012\n",
      "Epoch: 003, Train Acc: 0.4990, Test Acc: 0.5012\n",
      "Epoch: 004, Train Acc: 0.5317, Test Acc: 0.5588\n",
      "Epoch: 005, Train Acc: 0.5385, Test Acc: 0.5012\n",
      "Epoch: 006, Train Acc: 0.5400, Test Acc: 0.5081\n",
      "Epoch: 007, Train Acc: 0.5346, Test Acc: 0.5012\n",
      "Epoch: 008, Train Acc: 0.5521, Test Acc: 0.5230\n",
      "Epoch: 009, Train Acc: 0.5911, Test Acc: 0.5161\n",
      "Epoch: 010, Train Acc: 0.5941, Test Acc: 0.5726\n",
      "Epoch: 011, Train Acc: 0.5941, Test Acc: 0.5541\n",
      "Epoch: 012, Train Acc: 0.5892, Test Acc: 0.5288\n",
      "Epoch: 013, Train Acc: 0.5234, Test Acc: 0.5334\n",
      "Epoch: 014, Train Acc: 0.5911, Test Acc: 0.5380\n",
      "Epoch: 015, Train Acc: 0.5463, Test Acc: 0.5588\n",
      "Epoch: 016, Train Acc: 0.5833, Test Acc: 0.5841\n",
      "Epoch: 017, Train Acc: 0.5916, Test Acc: 0.5380\n",
      "Epoch: 018, Train Acc: 0.5180, Test Acc: 0.4988\n",
      "Epoch: 019, Train Acc: 0.5770, Test Acc: 0.5726\n",
      "Epoch: 020, Train Acc: 0.5814, Test Acc: 0.5818\n",
      "Epoch: 021, Train Acc: 0.5975, Test Acc: 0.5737\n",
      "Epoch: 022, Train Acc: 0.5970, Test Acc: 0.5956\n",
      "Epoch: 023, Train Acc: 0.5668, Test Acc: 0.5380\n",
      "Epoch: 024, Train Acc: 0.5999, Test Acc: 0.5853\n",
      "Epoch: 025, Train Acc: 0.5853, Test Acc: 0.5760\n",
      "Epoch: 026, Train Acc: 0.5687, Test Acc: 0.5599\n",
      "Epoch: 027, Train Acc: 0.6004, Test Acc: 0.6060\n",
      "Epoch: 028, Train Acc: 0.5034, Test Acc: 0.5081\n",
      "Epoch: 029, Train Acc: 0.5984, Test Acc: 0.5899\n",
      "Epoch: 030, Train Acc: 0.5814, Test Acc: 0.5472\n",
      "Epoch: 031, Train Acc: 0.5609, Test Acc: 0.5392\n",
      "Epoch: 032, Train Acc: 0.6038, Test Acc: 0.5876\n",
      "Epoch: 033, Train Acc: 0.5453, Test Acc: 0.5265\n",
      "Epoch: 034, Train Acc: 0.6043, Test Acc: 0.6014\n",
      "Epoch: 035, Train Acc: 0.6101, Test Acc: 0.6037\n",
      "Epoch: 036, Train Acc: 0.5902, Test Acc: 0.5864\n",
      "Epoch: 037, Train Acc: 0.6077, Test Acc: 0.5853\n",
      "Epoch: 038, Train Acc: 0.5955, Test Acc: 0.5968\n",
      "Epoch: 039, Train Acc: 0.6033, Test Acc: 0.6325\n",
      "Epoch: 040, Train Acc: 0.6111, Test Acc: 0.6336\n",
      "Epoch: 041, Train Acc: 0.5404, Test Acc: 0.5276\n",
      "Epoch: 042, Train Acc: 0.6087, Test Acc: 0.6290\n",
      "Epoch: 043, Train Acc: 0.6092, Test Acc: 0.6060\n",
      "Epoch: 044, Train Acc: 0.5960, Test Acc: 0.6060\n",
      "Epoch: 045, Train Acc: 0.5512, Test Acc: 0.5369\n",
      "Epoch: 046, Train Acc: 0.5404, Test Acc: 0.5265\n",
      "Epoch: 047, Train Acc: 0.6014, Test Acc: 0.5703\n",
      "Epoch: 048, Train Acc: 0.6053, Test Acc: 0.5806\n",
      "Epoch: 049, Train Acc: 0.5439, Test Acc: 0.5253\n",
      "Epoch: 050, Train Acc: 0.6019, Test Acc: 0.5772\n",
      "Epoch: 051, Train Acc: 0.5994, Test Acc: 0.5760\n",
      "Epoch: 052, Train Acc: 0.6053, Test Acc: 0.5979\n",
      "Epoch: 053, Train Acc: 0.5999, Test Acc: 0.5945\n",
      "Epoch: 054, Train Acc: 0.5984, Test Acc: 0.5864\n",
      "Epoch: 055, Train Acc: 0.6077, Test Acc: 0.6279\n",
      "Epoch: 056, Train Acc: 0.6053, Test Acc: 0.5853\n",
      "Epoch: 057, Train Acc: 0.6101, Test Acc: 0.6152\n",
      "Epoch: 058, Train Acc: 0.5999, Test Acc: 0.5910\n",
      "Epoch: 059, Train Acc: 0.5877, Test Acc: 0.5714\n",
      "Epoch: 060, Train Acc: 0.5902, Test Acc: 0.5691\n",
      "Epoch: 061, Train Acc: 0.6087, Test Acc: 0.5968\n",
      "Epoch: 062, Train Acc: 0.5828, Test Acc: 0.5703\n",
      "Epoch: 063, Train Acc: 0.6019, Test Acc: 0.6210\n",
      "Epoch: 064, Train Acc: 0.6009, Test Acc: 0.5818\n",
      "Epoch: 065, Train Acc: 0.5955, Test Acc: 0.5853\n",
      "Epoch: 066, Train Acc: 0.6072, Test Acc: 0.5829\n",
      "Epoch: 067, Train Acc: 0.6135, Test Acc: 0.6048\n",
      "Epoch: 068, Train Acc: 0.5867, Test Acc: 0.5841\n",
      "Epoch: 069, Train Acc: 0.5517, Test Acc: 0.5300\n",
      "Epoch: 070, Train Acc: 0.5853, Test Acc: 0.5611\n",
      "Epoch: 071, Train Acc: 0.6072, Test Acc: 0.6233\n",
      "Epoch: 072, Train Acc: 0.6019, Test Acc: 0.5853\n",
      "Epoch: 073, Train Acc: 0.5736, Test Acc: 0.5495\n",
      "Epoch: 074, Train Acc: 0.6101, Test Acc: 0.6060\n",
      "Epoch: 075, Train Acc: 0.5989, Test Acc: 0.5772\n",
      "Epoch: 076, Train Acc: 0.5843, Test Acc: 0.5622\n",
      "Epoch: 077, Train Acc: 0.6155, Test Acc: 0.5887\n",
      "Epoch: 078, Train Acc: 0.6155, Test Acc: 0.5795\n",
      "Epoch: 079, Train Acc: 0.6096, Test Acc: 0.6198\n",
      "Epoch: 080, Train Acc: 0.5858, Test Acc: 0.5622\n",
      "Epoch: 081, Train Acc: 0.6179, Test Acc: 0.6267\n",
      "Epoch: 082, Train Acc: 0.6199, Test Acc: 0.6313\n",
      "Epoch: 083, Train Acc: 0.5712, Test Acc: 0.5323\n",
      "Epoch: 084, Train Acc: 0.6028, Test Acc: 0.6141\n",
      "Epoch: 085, Train Acc: 0.5994, Test Acc: 0.5933\n",
      "Epoch: 086, Train Acc: 0.5980, Test Acc: 0.6002\n",
      "Epoch: 087, Train Acc: 0.6092, Test Acc: 0.6071\n",
      "Epoch: 088, Train Acc: 0.6019, Test Acc: 0.5703\n",
      "Epoch: 089, Train Acc: 0.6106, Test Acc: 0.5853\n",
      "Epoch: 090, Train Acc: 0.5872, Test Acc: 0.5576\n",
      "Epoch: 091, Train Acc: 0.6160, Test Acc: 0.5887\n",
      "Epoch: 092, Train Acc: 0.6150, Test Acc: 0.6198\n",
      "Epoch: 093, Train Acc: 0.6106, Test Acc: 0.5853\n",
      "Epoch: 094, Train Acc: 0.6184, Test Acc: 0.6048\n",
      "Epoch: 095, Train Acc: 0.6033, Test Acc: 0.6152\n",
      "Epoch: 096, Train Acc: 0.5921, Test Acc: 0.5749\n",
      "Epoch: 097, Train Acc: 0.5794, Test Acc: 0.5611\n",
      "Epoch: 098, Train Acc: 0.4990, Test Acc: 0.5012\n",
      "Epoch: 099, Train Acc: 0.5156, Test Acc: 0.5161\n",
      "Epoch: 100, Train Acc: 0.5029, Test Acc: 0.4988\n",
      "Epoch: 101, Train Acc: 0.5975, Test Acc: 0.5841\n",
      "Epoch: 102, Train Acc: 0.5536, Test Acc: 0.5288\n",
      "Epoch: 103, Train Acc: 0.5975, Test Acc: 0.5829\n",
      "Epoch: 104, Train Acc: 0.6009, Test Acc: 0.5829\n",
      "Epoch: 105, Train Acc: 0.5443, Test Acc: 0.5288\n",
      "Epoch: 106, Train Acc: 0.5941, Test Acc: 0.6083\n",
      "Epoch: 107, Train Acc: 0.5999, Test Acc: 0.5714\n",
      "Epoch: 108, Train Acc: 0.5984, Test Acc: 0.5645\n",
      "Epoch: 109, Train Acc: 0.5975, Test Acc: 0.5795\n",
      "Epoch: 110, Train Acc: 0.5984, Test Acc: 0.5668\n",
      "Epoch: 111, Train Acc: 0.6067, Test Acc: 0.5864\n",
      "Epoch: 112, Train Acc: 0.6019, Test Acc: 0.5657\n",
      "Epoch: 113, Train Acc: 0.6033, Test Acc: 0.5645\n",
      "Epoch: 114, Train Acc: 0.6067, Test Acc: 0.6048\n",
      "Epoch: 115, Train Acc: 0.5931, Test Acc: 0.5853\n",
      "Epoch: 116, Train Acc: 0.6043, Test Acc: 0.5818\n",
      "Epoch: 117, Train Acc: 0.6009, Test Acc: 0.5588\n",
      "Epoch: 118, Train Acc: 0.6092, Test Acc: 0.5714\n",
      "Epoch: 119, Train Acc: 0.6019, Test Acc: 0.6187\n",
      "Epoch: 120, Train Acc: 0.6121, Test Acc: 0.5876\n",
      "Epoch: 121, Train Acc: 0.6062, Test Acc: 0.5657\n",
      "Epoch: 122, Train Acc: 0.6106, Test Acc: 0.6002\n",
      "Epoch: 123, Train Acc: 0.6082, Test Acc: 0.5991\n",
      "Epoch: 124, Train Acc: 0.6087, Test Acc: 0.6048\n",
      "Epoch: 125, Train Acc: 0.6033, Test Acc: 0.6175\n",
      "Epoch: 126, Train Acc: 0.5770, Test Acc: 0.5541\n",
      "Epoch: 127, Train Acc: 0.6106, Test Acc: 0.6071\n",
      "Epoch: 128, Train Acc: 0.6062, Test Acc: 0.6164\n",
      "Epoch: 129, Train Acc: 0.6116, Test Acc: 0.6256\n",
      "Epoch: 130, Train Acc: 0.6106, Test Acc: 0.6221\n",
      "Epoch: 131, Train Acc: 0.5892, Test Acc: 0.5668\n",
      "Epoch: 132, Train Acc: 0.6121, Test Acc: 0.6152\n",
      "Epoch: 133, Train Acc: 0.6165, Test Acc: 0.6025\n",
      "Epoch: 134, Train Acc: 0.5926, Test Acc: 0.5622\n",
      "Epoch: 135, Train Acc: 0.6131, Test Acc: 0.5968\n",
      "Epoch: 136, Train Acc: 0.6048, Test Acc: 0.6175\n",
      "Epoch: 137, Train Acc: 0.6116, Test Acc: 0.6060\n",
      "Epoch: 138, Train Acc: 0.6092, Test Acc: 0.6071\n",
      "Epoch: 139, Train Acc: 0.6165, Test Acc: 0.5887\n",
      "Epoch: 140, Train Acc: 0.6004, Test Acc: 0.5714\n",
      "Epoch: 141, Train Acc: 0.6140, Test Acc: 0.5829\n",
      "Epoch: 142, Train Acc: 0.6126, Test Acc: 0.6083\n",
      "Epoch: 143, Train Acc: 0.6116, Test Acc: 0.6256\n",
      "Epoch: 144, Train Acc: 0.6106, Test Acc: 0.6164\n",
      "Epoch: 145, Train Acc: 0.5931, Test Acc: 0.5622\n",
      "Epoch: 146, Train Acc: 0.5984, Test Acc: 0.6083\n",
      "Epoch: 147, Train Acc: 0.6096, Test Acc: 0.5691\n",
      "Epoch: 148, Train Acc: 0.6155, Test Acc: 0.6210\n",
      "Epoch: 149, Train Acc: 0.6160, Test Acc: 0.5795\n",
      "Epoch: 150, Train Acc: 0.6048, Test Acc: 0.5703\n",
      "Epoch: 151, Train Acc: 0.6150, Test Acc: 0.5887\n",
      "Epoch: 152, Train Acc: 0.6126, Test Acc: 0.6233\n",
      "Epoch: 153, Train Acc: 0.6165, Test Acc: 0.5922\n",
      "Epoch: 154, Train Acc: 0.6150, Test Acc: 0.6256\n",
      "Epoch: 155, Train Acc: 0.5945, Test Acc: 0.5634\n",
      "Epoch: 156, Train Acc: 0.6145, Test Acc: 0.6198\n",
      "Epoch: 157, Train Acc: 0.5902, Test Acc: 0.5887\n",
      "Epoch: 158, Train Acc: 0.6019, Test Acc: 0.5726\n",
      "Epoch: 159, Train Acc: 0.5989, Test Acc: 0.5806\n",
      "Epoch: 160, Train Acc: 0.6174, Test Acc: 0.6210\n",
      "Epoch: 161, Train Acc: 0.5697, Test Acc: 0.5518\n",
      "Epoch: 162, Train Acc: 0.6160, Test Acc: 0.5991\n",
      "Epoch: 163, Train Acc: 0.6194, Test Acc: 0.6048\n",
      "Epoch: 164, Train Acc: 0.6223, Test Acc: 0.6336\n",
      "Epoch: 165, Train Acc: 0.5980, Test Acc: 0.6094\n",
      "Epoch: 166, Train Acc: 0.6092, Test Acc: 0.5760\n",
      "Epoch: 167, Train Acc: 0.6189, Test Acc: 0.6129\n",
      "Epoch: 168, Train Acc: 0.6150, Test Acc: 0.6106\n",
      "Epoch: 169, Train Acc: 0.6145, Test Acc: 0.6279\n",
      "Epoch: 170, Train Acc: 0.5960, Test Acc: 0.5991\n",
      "Epoch: 171, Train Acc: 0.6131, Test Acc: 0.6221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 172, Train Acc: 0.6082, Test Acc: 0.6210\n",
      "Epoch: 173, Train Acc: 0.6209, Test Acc: 0.6267\n",
      "Epoch: 174, Train Acc: 0.6204, Test Acc: 0.6071\n",
      "Epoch: 175, Train Acc: 0.6165, Test Acc: 0.6233\n",
      "Epoch: 176, Train Acc: 0.6160, Test Acc: 0.6129\n",
      "Epoch: 177, Train Acc: 0.5970, Test Acc: 0.5749\n",
      "Epoch: 178, Train Acc: 0.6179, Test Acc: 0.6048\n",
      "Epoch: 179, Train Acc: 0.6131, Test Acc: 0.6244\n",
      "Epoch: 180, Train Acc: 0.6170, Test Acc: 0.6002\n",
      "Epoch: 181, Train Acc: 0.6140, Test Acc: 0.6279\n",
      "Epoch: 182, Train Acc: 0.6121, Test Acc: 0.6221\n",
      "Epoch: 183, Train Acc: 0.6145, Test Acc: 0.5968\n",
      "Epoch: 184, Train Acc: 0.6199, Test Acc: 0.6325\n",
      "Epoch: 185, Train Acc: 0.5692, Test Acc: 0.5553\n",
      "Epoch: 186, Train Acc: 0.6087, Test Acc: 0.5749\n",
      "Epoch: 187, Train Acc: 0.6140, Test Acc: 0.6210\n",
      "Epoch: 188, Train Acc: 0.6194, Test Acc: 0.6002\n",
      "Epoch: 189, Train Acc: 0.5936, Test Acc: 0.5749\n",
      "Epoch: 190, Train Acc: 0.6174, Test Acc: 0.6325\n",
      "Epoch: 191, Train Acc: 0.6189, Test Acc: 0.6106\n",
      "Epoch: 192, Train Acc: 0.5916, Test Acc: 0.5599\n",
      "Epoch: 193, Train Acc: 0.6150, Test Acc: 0.6037\n",
      "Epoch: 194, Train Acc: 0.6209, Test Acc: 0.6118\n",
      "Epoch: 195, Train Acc: 0.6184, Test Acc: 0.6267\n",
      "Epoch: 196, Train Acc: 0.6218, Test Acc: 0.6060\n",
      "Epoch: 197, Train Acc: 0.6135, Test Acc: 0.6071\n",
      "Epoch: 198, Train Acc: 0.5999, Test Acc: 0.6141\n",
      "Epoch: 199, Train Acc: 0.6160, Test Acc: 0.6037\n",
      "Epoch: 200, Train Acc: 0.6145, Test Acc: 0.5887\n",
      "Epoch: 201, Train Acc: 0.6179, Test Acc: 0.6313\n",
      "Epoch: 202, Train Acc: 0.6145, Test Acc: 0.6267\n",
      "Epoch: 203, Train Acc: 0.5965, Test Acc: 0.5841\n",
      "Epoch: 204, Train Acc: 0.6189, Test Acc: 0.6302\n",
      "Epoch: 205, Train Acc: 0.6199, Test Acc: 0.6279\n",
      "Epoch: 206, Train Acc: 0.6252, Test Acc: 0.6290\n",
      "Epoch: 207, Train Acc: 0.6194, Test Acc: 0.6279\n",
      "Epoch: 208, Train Acc: 0.6204, Test Acc: 0.6290\n",
      "Epoch: 209, Train Acc: 0.6145, Test Acc: 0.6210\n",
      "Epoch: 210, Train Acc: 0.6228, Test Acc: 0.6348\n",
      "Epoch: 211, Train Acc: 0.6043, Test Acc: 0.6198\n",
      "Epoch: 212, Train Acc: 0.6213, Test Acc: 0.6106\n",
      "Epoch: 213, Train Acc: 0.6048, Test Acc: 0.6198\n",
      "Epoch: 214, Train Acc: 0.6072, Test Acc: 0.5876\n",
      "Epoch: 215, Train Acc: 0.6033, Test Acc: 0.5841\n",
      "Epoch: 216, Train Acc: 0.6038, Test Acc: 0.6221\n",
      "Epoch: 217, Train Acc: 0.5010, Test Acc: 0.4988\n",
      "Epoch: 218, Train Acc: 0.6296, Test Acc: 0.5956\n",
      "Epoch: 219, Train Acc: 0.5010, Test Acc: 0.4988\n",
      "Epoch: 220, Train Acc: 0.5019, Test Acc: 0.5023\n",
      "Epoch: 221, Train Acc: 0.4995, Test Acc: 0.5023\n",
      "Epoch: 222, Train Acc: 0.5487, Test Acc: 0.5069\n",
      "Epoch: 223, Train Acc: 0.5019, Test Acc: 0.5046\n",
      "Epoch: 224, Train Acc: 0.6092, Test Acc: 0.6164\n",
      "Epoch: 225, Train Acc: 0.5931, Test Acc: 0.6152\n",
      "Epoch: 226, Train Acc: 0.6067, Test Acc: 0.5899\n",
      "Epoch: 227, Train Acc: 0.6096, Test Acc: 0.5991\n",
      "Epoch: 228, Train Acc: 0.5950, Test Acc: 0.6141\n",
      "Epoch: 229, Train Acc: 0.6087, Test Acc: 0.5933\n",
      "Epoch: 230, Train Acc: 0.6087, Test Acc: 0.6118\n",
      "Epoch: 231, Train Acc: 0.5994, Test Acc: 0.6221\n",
      "Epoch: 232, Train Acc: 0.5819, Test Acc: 0.5588\n",
      "Epoch: 233, Train Acc: 0.5448, Test Acc: 0.5035\n",
      "Epoch: 234, Train Acc: 0.6009, Test Acc: 0.5749\n",
      "Epoch: 235, Train Acc: 0.6077, Test Acc: 0.5657\n",
      "Epoch: 236, Train Acc: 0.6121, Test Acc: 0.6060\n",
      "Epoch: 237, Train Acc: 0.5975, Test Acc: 0.5737\n",
      "Epoch: 238, Train Acc: 0.6004, Test Acc: 0.6175\n",
      "Epoch: 239, Train Acc: 0.5994, Test Acc: 0.6175\n",
      "Epoch: 240, Train Acc: 0.6135, Test Acc: 0.6118\n",
      "Epoch: 241, Train Acc: 0.6204, Test Acc: 0.6014\n",
      "Epoch: 242, Train Acc: 0.6165, Test Acc: 0.6279\n",
      "Epoch: 243, Train Acc: 0.5926, Test Acc: 0.5657\n",
      "Epoch: 244, Train Acc: 0.6155, Test Acc: 0.5991\n",
      "Epoch: 245, Train Acc: 0.6174, Test Acc: 0.6198\n",
      "Epoch: 246, Train Acc: 0.6111, Test Acc: 0.5749\n",
      "Epoch: 247, Train Acc: 0.6077, Test Acc: 0.5737\n",
      "Epoch: 248, Train Acc: 0.6213, Test Acc: 0.6141\n",
      "Epoch: 249, Train Acc: 0.5828, Test Acc: 0.5645\n",
      "Epoch: 250, Train Acc: 0.6199, Test Acc: 0.6256\n",
      "Epoch: 251, Train Acc: 0.6218, Test Acc: 0.6325\n",
      "Epoch: 252, Train Acc: 0.6189, Test Acc: 0.5991\n",
      "Epoch: 253, Train Acc: 0.6096, Test Acc: 0.5714\n",
      "Epoch: 254, Train Acc: 0.6131, Test Acc: 0.5760\n",
      "Epoch: 255, Train Acc: 0.6140, Test Acc: 0.5726\n",
      "Epoch: 256, Train Acc: 0.6228, Test Acc: 0.6313\n",
      "Epoch: 257, Train Acc: 0.6218, Test Acc: 0.6290\n",
      "Epoch: 258, Train Acc: 0.6150, Test Acc: 0.6002\n",
      "Epoch: 259, Train Acc: 0.6228, Test Acc: 0.6118\n",
      "Epoch: 260, Train Acc: 0.6228, Test Acc: 0.6118\n",
      "Epoch: 261, Train Acc: 0.6150, Test Acc: 0.6244\n",
      "Epoch: 262, Train Acc: 0.6189, Test Acc: 0.6256\n",
      "Epoch: 263, Train Acc: 0.6179, Test Acc: 0.6336\n",
      "Epoch: 264, Train Acc: 0.6218, Test Acc: 0.6244\n",
      "Epoch: 265, Train Acc: 0.6121, Test Acc: 0.5979\n",
      "Epoch: 266, Train Acc: 0.6209, Test Acc: 0.6129\n",
      "Epoch: 267, Train Acc: 0.6194, Test Acc: 0.5991\n",
      "Epoch: 268, Train Acc: 0.6043, Test Acc: 0.6187\n",
      "Epoch: 269, Train Acc: 0.6077, Test Acc: 0.5806\n",
      "Epoch: 270, Train Acc: 0.6014, Test Acc: 0.5772\n",
      "Epoch: 271, Train Acc: 0.6145, Test Acc: 0.5806\n",
      "Epoch: 272, Train Acc: 0.6218, Test Acc: 0.6325\n",
      "Epoch: 273, Train Acc: 0.6028, Test Acc: 0.5806\n",
      "Epoch: 274, Train Acc: 0.6194, Test Acc: 0.6083\n",
      "Epoch: 275, Train Acc: 0.6126, Test Acc: 0.5933\n",
      "Epoch: 276, Train Acc: 0.6043, Test Acc: 0.5737\n",
      "Epoch: 277, Train Acc: 0.6218, Test Acc: 0.6325\n",
      "Epoch: 278, Train Acc: 0.6204, Test Acc: 0.6106\n",
      "Epoch: 279, Train Acc: 0.6174, Test Acc: 0.6233\n",
      "Epoch: 280, Train Acc: 0.6189, Test Acc: 0.6279\n",
      "Epoch: 281, Train Acc: 0.6038, Test Acc: 0.5829\n",
      "Epoch: 282, Train Acc: 0.5331, Test Acc: 0.5150\n",
      "Epoch: 283, Train Acc: 0.6160, Test Acc: 0.5933\n",
      "Epoch: 284, Train Acc: 0.6174, Test Acc: 0.5968\n",
      "Epoch: 285, Train Acc: 0.6160, Test Acc: 0.5772\n",
      "Epoch: 286, Train Acc: 0.5785, Test Acc: 0.5565\n",
      "Epoch: 287, Train Acc: 0.6218, Test Acc: 0.6106\n",
      "Epoch: 288, Train Acc: 0.6223, Test Acc: 0.6279\n",
      "Epoch: 289, Train Acc: 0.6179, Test Acc: 0.6313\n",
      "Epoch: 290, Train Acc: 0.6223, Test Acc: 0.6141\n",
      "Epoch: 291, Train Acc: 0.6194, Test Acc: 0.6175\n",
      "Epoch: 292, Train Acc: 0.6262, Test Acc: 0.6267\n",
      "Epoch: 293, Train Acc: 0.6179, Test Acc: 0.5910\n",
      "Epoch: 294, Train Acc: 0.6218, Test Acc: 0.6187\n",
      "Epoch: 295, Train Acc: 0.6121, Test Acc: 0.6198\n",
      "Epoch: 296, Train Acc: 0.6072, Test Acc: 0.6210\n",
      "Epoch: 297, Train Acc: 0.6228, Test Acc: 0.6071\n",
      "Epoch: 298, Train Acc: 0.6067, Test Acc: 0.6210\n",
      "Epoch: 299, Train Acc: 0.6209, Test Acc: 0.6152\n",
      "Epoch: 300, Train Acc: 0.6296, Test Acc: 0.6359\n",
      "Epoch: 301, Train Acc: 0.6282, Test Acc: 0.6382\n",
      "Epoch: 302, Train Acc: 0.6238, Test Acc: 0.6256\n",
      "Epoch: 303, Train Acc: 0.6096, Test Acc: 0.6175\n",
      "Epoch: 304, Train Acc: 0.5970, Test Acc: 0.6152\n",
      "Epoch: 305, Train Acc: 0.6019, Test Acc: 0.6175\n",
      "Epoch: 306, Train Acc: 0.6116, Test Acc: 0.5772\n",
      "Epoch: 307, Train Acc: 0.6082, Test Acc: 0.6244\n",
      "Epoch: 308, Train Acc: 0.6174, Test Acc: 0.6267\n",
      "Epoch: 309, Train Acc: 0.6077, Test Acc: 0.6198\n",
      "Epoch: 310, Train Acc: 0.6155, Test Acc: 0.6025\n",
      "Epoch: 311, Train Acc: 0.6140, Test Acc: 0.6267\n",
      "Epoch: 312, Train Acc: 0.6145, Test Acc: 0.5772\n",
      "Epoch: 313, Train Acc: 0.6199, Test Acc: 0.6060\n",
      "Epoch: 314, Train Acc: 0.6238, Test Acc: 0.5991\n",
      "Epoch: 315, Train Acc: 0.6223, Test Acc: 0.6348\n",
      "Epoch: 316, Train Acc: 0.6209, Test Acc: 0.5876\n",
      "Epoch: 317, Train Acc: 0.6140, Test Acc: 0.5749\n",
      "Epoch: 318, Train Acc: 0.6160, Test Acc: 0.5680\n",
      "Epoch: 319, Train Acc: 0.6223, Test Acc: 0.6313\n",
      "Epoch: 320, Train Acc: 0.6257, Test Acc: 0.5841\n",
      "Epoch: 321, Train Acc: 0.6184, Test Acc: 0.6129\n",
      "Epoch: 322, Train Acc: 0.6228, Test Acc: 0.6256\n",
      "Epoch: 323, Train Acc: 0.6218, Test Acc: 0.5945\n",
      "Epoch: 324, Train Acc: 0.5653, Test Acc: 0.5346\n",
      "Epoch: 325, Train Acc: 0.6179, Test Acc: 0.6313\n",
      "Epoch: 326, Train Acc: 0.6243, Test Acc: 0.6313\n",
      "Epoch: 327, Train Acc: 0.6145, Test Acc: 0.6244\n",
      "Epoch: 328, Train Acc: 0.6199, Test Acc: 0.5922\n",
      "Epoch: 329, Train Acc: 0.6213, Test Acc: 0.6198\n",
      "Epoch: 330, Train Acc: 0.6218, Test Acc: 0.6141\n",
      "Epoch: 331, Train Acc: 0.6223, Test Acc: 0.6164\n",
      "Epoch: 332, Train Acc: 0.6238, Test Acc: 0.6129\n",
      "Epoch: 333, Train Acc: 0.6301, Test Acc: 0.6210\n",
      "Epoch: 334, Train Acc: 0.6101, Test Acc: 0.5703\n",
      "Epoch: 335, Train Acc: 0.6087, Test Acc: 0.5737\n",
      "Epoch: 336, Train Acc: 0.6238, Test Acc: 0.6164\n",
      "Epoch: 337, Train Acc: 0.6277, Test Acc: 0.6152\n",
      "Epoch: 338, Train Acc: 0.6189, Test Acc: 0.6348\n",
      "Epoch: 339, Train Acc: 0.6209, Test Acc: 0.6210\n",
      "Epoch: 340, Train Acc: 0.6218, Test Acc: 0.6187\n",
      "Epoch: 341, Train Acc: 0.5926, Test Acc: 0.6014\n",
      "Epoch: 342, Train Acc: 0.6277, Test Acc: 0.6382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 343, Train Acc: 0.6291, Test Acc: 0.6406\n",
      "Epoch: 344, Train Acc: 0.6287, Test Acc: 0.6382\n",
      "Epoch: 345, Train Acc: 0.6291, Test Acc: 0.5829\n",
      "Epoch: 346, Train Acc: 0.6111, Test Acc: 0.5737\n",
      "Epoch: 347, Train Acc: 0.6267, Test Acc: 0.6325\n",
      "Epoch: 348, Train Acc: 0.6053, Test Acc: 0.6233\n",
      "Epoch: 349, Train Acc: 0.6267, Test Acc: 0.6244\n",
      "Epoch: 350, Train Acc: 0.5999, Test Acc: 0.5657\n",
      "Epoch: 351, Train Acc: 0.6287, Test Acc: 0.5841\n",
      "Epoch: 352, Train Acc: 0.6038, Test Acc: 0.5703\n",
      "Epoch: 353, Train Acc: 0.6277, Test Acc: 0.5945\n",
      "Epoch: 354, Train Acc: 0.6243, Test Acc: 0.6198\n",
      "Epoch: 355, Train Acc: 0.6243, Test Acc: 0.6221\n",
      "Epoch: 356, Train Acc: 0.6179, Test Acc: 0.6175\n",
      "Epoch: 357, Train Acc: 0.6204, Test Acc: 0.6336\n",
      "Epoch: 358, Train Acc: 0.6126, Test Acc: 0.6267\n",
      "Epoch: 359, Train Acc: 0.6121, Test Acc: 0.6221\n",
      "Epoch: 360, Train Acc: 0.6199, Test Acc: 0.6348\n",
      "Epoch: 361, Train Acc: 0.6101, Test Acc: 0.6302\n",
      "Epoch: 362, Train Acc: 0.5161, Test Acc: 0.5046\n",
      "Epoch: 363, Train Acc: 0.6014, Test Acc: 0.5507\n",
      "Epoch: 364, Train Acc: 0.5887, Test Acc: 0.5184\n",
      "Epoch: 365, Train Acc: 0.6072, Test Acc: 0.5864\n",
      "Epoch: 366, Train Acc: 0.6077, Test Acc: 0.5899\n",
      "Epoch: 367, Train Acc: 0.6082, Test Acc: 0.5806\n",
      "Epoch: 368, Train Acc: 0.6126, Test Acc: 0.6014\n",
      "Epoch: 369, Train Acc: 0.6179, Test Acc: 0.5956\n",
      "Epoch: 370, Train Acc: 0.6048, Test Acc: 0.5749\n",
      "Epoch: 371, Train Acc: 0.6218, Test Acc: 0.6187\n",
      "Epoch: 372, Train Acc: 0.6262, Test Acc: 0.5991\n",
      "Epoch: 373, Train Acc: 0.6135, Test Acc: 0.5760\n",
      "Epoch: 374, Train Acc: 0.6204, Test Acc: 0.6348\n",
      "Epoch: 375, Train Acc: 0.6252, Test Acc: 0.5737\n",
      "Epoch: 376, Train Acc: 0.6223, Test Acc: 0.6382\n",
      "Epoch: 377, Train Acc: 0.6209, Test Acc: 0.6256\n",
      "Epoch: 378, Train Acc: 0.5575, Test Acc: 0.5173\n",
      "Epoch: 379, Train Acc: 0.6121, Test Acc: 0.6313\n",
      "Epoch: 380, Train Acc: 0.6277, Test Acc: 0.6025\n",
      "Epoch: 381, Train Acc: 0.6306, Test Acc: 0.6152\n",
      "Epoch: 382, Train Acc: 0.6067, Test Acc: 0.6267\n",
      "Epoch: 383, Train Acc: 0.6243, Test Acc: 0.6256\n",
      "Epoch: 384, Train Acc: 0.6194, Test Acc: 0.6382\n",
      "Epoch: 385, Train Acc: 0.6248, Test Acc: 0.6406\n",
      "Epoch: 386, Train Acc: 0.6194, Test Acc: 0.6429\n",
      "Epoch: 387, Train Acc: 0.6194, Test Acc: 0.6417\n",
      "Epoch: 388, Train Acc: 0.6257, Test Acc: 0.6152\n",
      "Epoch: 389, Train Acc: 0.6228, Test Acc: 0.6463\n",
      "Epoch: 390, Train Acc: 0.6228, Test Acc: 0.6406\n",
      "Epoch: 391, Train Acc: 0.6291, Test Acc: 0.6394\n",
      "Epoch: 392, Train Acc: 0.6379, Test Acc: 0.6233\n",
      "Epoch: 393, Train Acc: 0.6311, Test Acc: 0.6382\n",
      "Epoch: 394, Train Acc: 0.6238, Test Acc: 0.6509\n",
      "Epoch: 395, Train Acc: 0.6321, Test Acc: 0.6233\n",
      "Epoch: 396, Train Acc: 0.5848, Test Acc: 0.5553\n",
      "Epoch: 397, Train Acc: 0.6296, Test Acc: 0.6336\n",
      "Epoch: 398, Train Acc: 0.6282, Test Acc: 0.6233\n",
      "Epoch: 399, Train Acc: 0.5853, Test Acc: 0.5588\n",
      "Epoch: 400, Train Acc: 0.6452, Test Acc: 0.6267\n",
      "Epoch: 401, Train Acc: 0.6418, Test Acc: 0.6094\n",
      "Epoch: 402, Train Acc: 0.6233, Test Acc: 0.6509\n",
      "Epoch: 403, Train Acc: 0.6306, Test Acc: 0.6406\n",
      "Epoch: 404, Train Acc: 0.6438, Test Acc: 0.6152\n",
      "Epoch: 405, Train Acc: 0.6355, Test Acc: 0.6452\n",
      "Epoch: 406, Train Acc: 0.6379, Test Acc: 0.6371\n",
      "Epoch: 407, Train Acc: 0.6306, Test Acc: 0.6475\n",
      "Epoch: 408, Train Acc: 0.6248, Test Acc: 0.6279\n",
      "Epoch: 409, Train Acc: 0.6267, Test Acc: 0.6071\n",
      "Epoch: 410, Train Acc: 0.6379, Test Acc: 0.6429\n",
      "Epoch: 411, Train Acc: 0.6282, Test Acc: 0.5968\n",
      "Epoch: 412, Train Acc: 0.6360, Test Acc: 0.6382\n",
      "Epoch: 413, Train Acc: 0.6218, Test Acc: 0.6475\n",
      "Epoch: 414, Train Acc: 0.6311, Test Acc: 0.6406\n",
      "Epoch: 415, Train Acc: 0.6384, Test Acc: 0.6509\n",
      "Epoch: 416, Train Acc: 0.6447, Test Acc: 0.6509\n",
      "Epoch: 417, Train Acc: 0.6296, Test Acc: 0.6429\n",
      "Epoch: 418, Train Acc: 0.6384, Test Acc: 0.6037\n",
      "Epoch: 419, Train Acc: 0.6326, Test Acc: 0.6382\n",
      "Epoch: 420, Train Acc: 0.5965, Test Acc: 0.5714\n",
      "Epoch: 421, Train Acc: 0.6306, Test Acc: 0.6429\n",
      "Epoch: 422, Train Acc: 0.6452, Test Acc: 0.6141\n",
      "Epoch: 423, Train Acc: 0.6350, Test Acc: 0.6094\n",
      "Epoch: 424, Train Acc: 0.6413, Test Acc: 0.6025\n",
      "Epoch: 425, Train Acc: 0.6223, Test Acc: 0.5841\n",
      "Epoch: 426, Train Acc: 0.6053, Test Acc: 0.5806\n",
      "Epoch: 427, Train Acc: 0.5931, Test Acc: 0.6164\n",
      "Epoch: 428, Train Acc: 0.6350, Test Acc: 0.6048\n",
      "Epoch: 429, Train Acc: 0.6321, Test Acc: 0.6060\n",
      "Epoch: 430, Train Acc: 0.6404, Test Acc: 0.6060\n",
      "Epoch: 431, Train Acc: 0.6272, Test Acc: 0.6394\n",
      "Epoch: 432, Train Acc: 0.6228, Test Acc: 0.5933\n",
      "Epoch: 433, Train Acc: 0.6365, Test Acc: 0.6175\n",
      "Epoch: 434, Train Acc: 0.6048, Test Acc: 0.6210\n",
      "Epoch: 435, Train Acc: 0.6209, Test Acc: 0.6002\n",
      "Epoch: 436, Train Acc: 0.6384, Test Acc: 0.6336\n",
      "Epoch: 437, Train Acc: 0.6291, Test Acc: 0.6406\n",
      "Epoch: 438, Train Acc: 0.6360, Test Acc: 0.6394\n",
      "Epoch: 439, Train Acc: 0.5809, Test Acc: 0.5714\n",
      "Epoch: 440, Train Acc: 0.6481, Test Acc: 0.6152\n",
      "Epoch: 441, Train Acc: 0.6457, Test Acc: 0.6290\n",
      "Epoch: 442, Train Acc: 0.6428, Test Acc: 0.6429\n",
      "Epoch: 443, Train Acc: 0.6213, Test Acc: 0.6463\n",
      "Epoch: 444, Train Acc: 0.6413, Test Acc: 0.6498\n",
      "Epoch: 445, Train Acc: 0.6462, Test Acc: 0.6325\n",
      "Epoch: 446, Train Acc: 0.6413, Test Acc: 0.6175\n",
      "Epoch: 447, Train Acc: 0.6413, Test Acc: 0.6475\n",
      "Epoch: 448, Train Acc: 0.6360, Test Acc: 0.6475\n",
      "Epoch: 449, Train Acc: 0.6418, Test Acc: 0.6279\n",
      "Epoch: 450, Train Acc: 0.6447, Test Acc: 0.6498\n",
      "Epoch: 451, Train Acc: 0.6053, Test Acc: 0.6290\n",
      "Epoch: 452, Train Acc: 0.6394, Test Acc: 0.6429\n",
      "Epoch: 453, Train Acc: 0.6306, Test Acc: 0.6267\n",
      "Epoch: 454, Train Acc: 0.6535, Test Acc: 0.6279\n",
      "Epoch: 455, Train Acc: 0.6384, Test Acc: 0.6578\n",
      "Epoch: 456, Train Acc: 0.6501, Test Acc: 0.6555\n",
      "Epoch: 457, Train Acc: 0.6218, Test Acc: 0.6348\n",
      "Epoch: 458, Train Acc: 0.6282, Test Acc: 0.6463\n",
      "Epoch: 459, Train Acc: 0.6428, Test Acc: 0.6601\n",
      "Epoch: 460, Train Acc: 0.6399, Test Acc: 0.6601\n",
      "Epoch: 461, Train Acc: 0.6321, Test Acc: 0.6521\n",
      "Epoch: 462, Train Acc: 0.6340, Test Acc: 0.6555\n",
      "Epoch: 463, Train Acc: 0.6384, Test Acc: 0.6578\n",
      "Epoch: 464, Train Acc: 0.6438, Test Acc: 0.6671\n",
      "Epoch: 465, Train Acc: 0.6408, Test Acc: 0.6417\n",
      "Epoch: 466, Train Acc: 0.6555, Test Acc: 0.6532\n",
      "Epoch: 467, Train Acc: 0.6174, Test Acc: 0.6417\n",
      "Epoch: 468, Train Acc: 0.6394, Test Acc: 0.6578\n",
      "Epoch: 469, Train Acc: 0.6594, Test Acc: 0.6601\n",
      "Epoch: 470, Train Acc: 0.6720, Test Acc: 0.6671\n",
      "Epoch: 471, Train Acc: 0.6613, Test Acc: 0.6590\n",
      "Epoch: 472, Train Acc: 0.6589, Test Acc: 0.6947\n",
      "Epoch: 473, Train Acc: 0.6672, Test Acc: 0.6624\n",
      "Epoch: 474, Train Acc: 0.6442, Test Acc: 0.6567\n",
      "Epoch: 475, Train Acc: 0.6633, Test Acc: 0.6486\n",
      "Epoch: 476, Train Acc: 0.6418, Test Acc: 0.6717\n",
      "Epoch: 477, Train Acc: 0.6174, Test Acc: 0.6141\n",
      "Epoch: 478, Train Acc: 0.6837, Test Acc: 0.6567\n",
      "Epoch: 479, Train Acc: 0.6657, Test Acc: 0.6452\n",
      "Epoch: 480, Train Acc: 0.6754, Test Acc: 0.6417\n",
      "Epoch: 481, Train Acc: 0.6862, Test Acc: 0.6671\n",
      "Epoch: 482, Train Acc: 0.6735, Test Acc: 0.6682\n",
      "Epoch: 483, Train Acc: 0.6662, Test Acc: 0.6532\n",
      "Epoch: 484, Train Acc: 0.6618, Test Acc: 0.6486\n",
      "Epoch: 485, Train Acc: 0.6628, Test Acc: 0.6440\n",
      "Epoch: 486, Train Acc: 0.6486, Test Acc: 0.6532\n",
      "Epoch: 487, Train Acc: 0.6525, Test Acc: 0.6440\n",
      "Epoch: 488, Train Acc: 0.6477, Test Acc: 0.6555\n",
      "Epoch: 489, Train Acc: 0.6837, Test Acc: 0.6463\n",
      "Epoch: 490, Train Acc: 0.6525, Test Acc: 0.6486\n",
      "Epoch: 491, Train Acc: 0.6740, Test Acc: 0.6613\n",
      "Epoch: 492, Train Acc: 0.6876, Test Acc: 0.6509\n",
      "Epoch: 493, Train Acc: 0.6516, Test Acc: 0.6429\n",
      "Epoch: 494, Train Acc: 0.6496, Test Acc: 0.6336\n",
      "Epoch: 495, Train Acc: 0.6525, Test Acc: 0.6578\n",
      "Epoch: 496, Train Acc: 0.6603, Test Acc: 0.6498\n",
      "Epoch: 497, Train Acc: 0.6116, Test Acc: 0.5853\n",
      "Epoch: 498, Train Acc: 0.6457, Test Acc: 0.6336\n",
      "Epoch: 499, Train Acc: 0.6559, Test Acc: 0.6302\n",
      "Best test accuracy - 0.6947004608294931 on epoch 472 with train accuracy - 0.6588693957115009\n"
     ]
    }
   ],
   "source": [
    "best_train, cur_epoch, best_val = -1, -1, -1 \n",
    "for epoch in range(1, 500):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    best_train, cur_epoch, best_val = (train_acc, epoch, test_acc) if test_acc > best_val \\\n",
    "                                    else (best_train, cur_epoch, best_val)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "print(f'Best test accuracy - {best_val} on epoch {cur_epoch} with train accuracy - {best_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb52030",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76791d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.load('test_full_data.npy', allow_pickle = True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12feb19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "health = 0\n",
    "mdd = 0\n",
    "for elem in t.keys():\n",
    "    if t[elem][1] == 0:\n",
    "        health += 1\n",
    "    elif t[elem][1] == 1:\n",
    "        mdd += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b97b8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "599669a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed21414c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590.9200000000001"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(433 + 436) * 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e3967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
