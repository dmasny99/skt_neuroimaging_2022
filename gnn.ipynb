{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc527ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import os\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "from IPython.display import Javascript\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv,SAGEConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e8837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patients = set(['F117', 'F130', 'F128', 'F133', 'F135', 'F138', 'F139', 'F136',\n",
    "                 'F131', 'F344', 'F504', 'F510', 'M512', 'F341', 'F337', 'F324',\n",
    "                 'F308', 'F317'])\n",
    "elecs = ['Fp1', 'Fp2', 'Fpz', 'F3', 'F4', 'Fz', 'C3', 'C4',\n",
    "         'Cz', 'P3', 'P4', 'Pz', '01', '02', '0z', 'F7', \n",
    "         'F8', 'T3', 'T4','T5', 'T6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea72af51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmasny\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/notebooks/gnn_eeg/wandb/run-20221027_205445-2aaruzmh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dmasny/neuroimaging_gnn_eeg_final_project/runs/2aaruzmh\" target=\"_blank\">winter-waterfall-39</a></strong> to <a href=\"https://wandb.ai/dmasny/neuroimaging_gnn_eeg_final_project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dmasny/neuroimaging_gnn_eeg_final_project/runs/2aaruzmh?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff9e7ffcc70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project = \"neuroimaging_gnn_eeg_final_project\", entity = \"dmasny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34aa1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNDataset(InMemoryDataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 root, \n",
    "                 data_dict, \n",
    "                 idx, \n",
    "                 feature_names, \n",
    "                 allow_loops, \n",
    "                 weighted, \n",
    "                 threshold = 0.65,\n",
    "                 transform = None, \n",
    "                 pre_transform = None, \n",
    "                 pre_filter = None):\n",
    "        \n",
    "        self.data = np.load(data_dict, allow_pickle = True).item()\n",
    "        self.stage = idx # idx 0 - train, idx 1 - test\n",
    "        self.feature_names = feature_names\n",
    "        self.allow_loops = allow_loops\n",
    "        self.weighted = weighted\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[self.stage])\n",
    "        \n",
    "    def vectorize_adj_mat_coo(self, matrix, allow_loops = True):\n",
    "        source_nodes = []\n",
    "        target_nodes = []\n",
    "        if allow_loops:\n",
    "            for i in range(matrix.shape[0]):\n",
    "                for j in range(i, matrix.shape[1]):\n",
    "                    source_nodes.append(i)\n",
    "                    target_nodes.append(j)\n",
    "        else:\n",
    "            for i in range(matrix.shape[0]):\n",
    "                for j in range(i + 1, matrix.shape[1]):\n",
    "                    source_nodes.append(i)\n",
    "                    target_nodes.append(j)\n",
    "        return source_nodes, target_nodes\n",
    "\n",
    "    def vectorize_adj_mat_weights(self, matrix):\n",
    "        edge_weights = []\n",
    "        if self.weighted == 'weighted':\n",
    "            if self.allow_loops:\n",
    "                for i in range(matrix.shape[0]):\n",
    "                    for j in range(i, matrix.shape[1]):\n",
    "                        edge_weights.append(matrix[i][j])\n",
    "            else:\n",
    "                for i in range(matrix.shape[0]):\n",
    "                    for j in range(i + 1, matrix.shape[1]):\n",
    "                        edge_weights.append(matrix[i][j])\n",
    "        else:\n",
    "            threshold = np.min(np.max(matrix, axis = 1)) if self.weighted == 'unweighted_dynamic_threshold' else self.threshold\n",
    "            mask = np.array((matrix > threshold), dtype = np.uint8)\n",
    "            if allow_loops:\n",
    "                for i in range(mask.shape[0]):\n",
    "                    for j in range(i, mask.shape[1]):\n",
    "                        edge_weights.append(mask[i][j])\n",
    "            else:\n",
    "                for i in range(mask.shape[0]):\n",
    "                    for j in range(i + 1, mask.shape[1]):\n",
    "                        edge_weights.append(mask[i][j])\n",
    "        return edge_weights\n",
    "\n",
    "    def upload_data(self, patch_name):\n",
    "        '''\n",
    "        input:\n",
    "            path_to_data: path to precomputed node representations\n",
    "            path_to_adj_matr: path to precomputed adj matrices\n",
    "            \n",
    "        returns:\n",
    "            Pygeometric Data object (see PyG docs)\n",
    "        '''\n",
    "        X, target, adj_matrix = self.data[patch_name] # triplet in format [X, target, A]\n",
    "        edge_index = np.array(self.vectorize_adj_mat_coo(adj_matrix))\n",
    "        edge_features = self.vectorize_adj_mat_weights(adj_matrix)\n",
    "        return Data(x = torch.tensor(X), \n",
    "                    edge_index = torch.tensor(edge_index),\n",
    "                    edge_attrs = edge_features, \n",
    "                    y = torch.tensor([target]))  \n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'gnn_dataset_train_{self.feature_names}.pt',\n",
    "                f'gnn_dataset_test_{self.feature_names}.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "        \n",
    "    def process(self):\n",
    "        data_list = []\n",
    "        for elem in self.data.keys():\n",
    "            data_list.append(self.upload_data(elem))\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[self.stage])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b5dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels, output_dim = 2):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(2022)\n",
    "        self.conv1 = SAGEConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.linear = Linear(hidden_channels, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.conv4(x ,edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "\n",
    "        # Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        # Classifier\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e1720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, \n",
    "          epoches, \n",
    "          criterion, \n",
    "          train_dataloader, \n",
    "          test_dataloader, \n",
    "          expirement_name, \n",
    "          path_to_save_weights = 'model_weights'):\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    for i in range(epoches):\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_loss = 0\n",
    "        for data in train_dataloader:\n",
    "            out = model(data.x.type(dtype = torch.float), \n",
    "                        data.edge_index, \n",
    "                        data.batch)  \n",
    "            loss = criterion(out, data.y) \n",
    "            train_loss += loss\n",
    "            pred = out.argmax(dim = 1)\n",
    "            train_correct += int((pred == data.y).sum())\n",
    "            loss.backward() \n",
    "            optimizer.step()  \n",
    "            optimizer.zero_grad() \n",
    "        train_loss = train_loss / len(train_dataloader.dataset)\n",
    "        train_accuracy = train_correct / len(train_dataloader.dataset)\n",
    "        \n",
    "        wandb.log({'train_loss': train_loss})\n",
    "        wandb.log({'train_accuracy': train_accuracy})\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():  \n",
    "            test_correct = 0\n",
    "            for data in test_dataloader:  \n",
    "                out = model(data.x.type(dtype = torch.float), data.edge_index, data.batch)  \n",
    "                pred = out.argmax(dim = 1)  \n",
    "                test_correct += int((pred == data.y).sum())\n",
    "            test_accuracy = test_correct / len(test_dataloader.dataset)\n",
    "            \n",
    "            if test_accuracy > best_accuracy:\n",
    "                best_accuracy = test_accuracy\n",
    "                torch.save(model.state_dict(), f'{path_to_save_weights}/{expirement_name}.pth')\n",
    "                \n",
    "            print(f'Epoch:{i} Train acc:{train_accuracy} Test acc:{test_accuracy} Train loss:{train_loss}')\n",
    "            \n",
    "            wandb.log({'test_accuracy': test_accuracy})\n",
    "            wandb.log({'best_test_accuracy': best_accuracy})\n",
    "            \n",
    "    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc70fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2aaruzmh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">winter-waterfall-39</strong>: <a href=\"https://wandb.ai/dmasny/neuroimaging_gnn_eeg_final_project/runs/2aaruzmh\" target=\"_blank\">https://wandb.ai/dmasny/neuroimaging_gnn_eeg_final_project/runs/2aaruzmh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221027_205445-2aaruzmh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2aaruzmh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405aea2a7470470e8bed06735ef88f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669110162183642, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/notebooks/gnn_eeg/wandb/run-20221027_205502-3bm3c9ul</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dmasny/neuroimaging_gnn_eeg_final_project/runs/3bm3c9ul\" target=\"_blank\">self_loops=True_weighted=weighted_data=power_and_entropy</a></strong> to <a href=\"https://wandb.ai/dmasny/neuroimaging_gnn_eeg_final_project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Train acc:0.49415204678362573 Test acc:0.4988479262672811 Train loss:0.014838864095509052\n",
      "Epoch:1 Train acc:0.5112085769980507 Test acc:0.5011520737327189 Train loss:0.014280869625508785\n",
      "Epoch:2 Train acc:0.5082846003898636 Test acc:0.4988479262672811 Train loss:0.014163868501782417\n",
      "Epoch:3 Train acc:0.49171539961013644 Test acc:0.4988479262672811 Train loss:0.014291990548372269\n",
      "Epoch:4 Train acc:0.5160818713450293 Test acc:0.5011520737327189 Train loss:0.01417999155819416\n",
      "Epoch:5 Train acc:0.5384990253411306 Test acc:0.5011520737327189 Train loss:0.014096962288022041\n",
      "Epoch:6 Train acc:0.5014619883040936 Test acc:0.5011520737327189 Train loss:0.014203084632754326\n",
      "Epoch:7 Train acc:0.5307017543859649 Test acc:0.5011520737327189 Train loss:0.014203093945980072\n",
      "Epoch:8 Train acc:0.5389863547758285 Test acc:0.5023041474654378 Train loss:0.014072886668145657\n",
      "Epoch:9 Train acc:0.5477582846003899 Test acc:0.5702764976958525 Train loss:0.013991250656545162\n",
      "Epoch:10 Train acc:0.5477582846003899 Test acc:0.5806451612903226 Train loss:0.013967608101665974\n",
      "Epoch:11 Train acc:0.5584795321637427 Test acc:0.533410138248848 Train loss:0.013934594579041004\n",
      "Epoch:12 Train acc:0.5623781676413255 Test acc:0.5207373271889401 Train loss:0.013935107737779617\n",
      "Epoch:13 Train acc:0.5609161793372319 Test acc:0.5794930875576036 Train loss:0.013956851325929165\n",
      "Epoch:14 Train acc:0.5735867446393762 Test acc:0.521889400921659 Train loss:0.013858837075531483\n",
      "Epoch:15 Train acc:0.5462962962962963 Test acc:0.4827188940092166 Train loss:0.014168458990752697\n",
      "Epoch:16 Train acc:0.5092592592592593 Test acc:0.511520737327189 Train loss:0.01450622733682394\n",
      "Epoch:17 Train acc:0.5667641325536062 Test acc:0.511520737327189 Train loss:0.013809554278850555\n",
      "Epoch:18 Train acc:0.5570175438596491 Test acc:0.5149769585253456 Train loss:0.014066047966480255\n",
      "Epoch:19 Train acc:0.5716374269005848 Test acc:0.5633640552995391 Train loss:0.013790042139589787\n",
      "Epoch:20 Train acc:0.5799220272904484 Test acc:0.5691244239631337 Train loss:0.013630262576043606\n",
      "Epoch:21 Train acc:0.5735867446393762 Test acc:0.5610599078341014 Train loss:0.013618316501379013\n",
      "Epoch:22 Train acc:0.5935672514619883 Test acc:0.5391705069124424 Train loss:0.01339927688241005\n",
      "Epoch:23 Train acc:0.5960038986354775 Test acc:0.5702764976958525 Train loss:0.013700583018362522\n",
      "Epoch:24 Train acc:0.526803118908382 Test acc:0.5748847926267281 Train loss:0.014009484089910984\n",
      "Epoch:25 Train acc:0.5994152046783626 Test acc:0.5737327188940092 Train loss:0.013736508786678314\n",
      "Epoch:26 Train acc:0.5311890838206628 Test acc:0.4988479262672811 Train loss:0.013985405676066875\n",
      "Epoch:27 Train acc:0.5847953216374269 Test acc:0.5564516129032258 Train loss:0.013559376820921898\n",
      "Epoch:28 Train acc:0.5999025341130604 Test acc:0.5299539170506913 Train loss:0.013312580063939095\n",
      "Epoch:29 Train acc:0.5501949317738791 Test acc:0.5714285714285714 Train loss:0.013961254619061947\n",
      "Epoch:30 Train acc:0.5833333333333334 Test acc:0.5011520737327189 Train loss:0.013411936350166798\n",
      "Epoch:31 Train acc:0.5555555555555556 Test acc:0.5771889400921659 Train loss:0.01373861450701952\n",
      "Epoch:32 Train acc:0.5672514619883041 Test acc:0.533410138248848 Train loss:0.013560964725911617\n",
      "Epoch:33 Train acc:0.5706627680311891 Test acc:0.5552995391705069 Train loss:0.013449734076857567\n",
      "Epoch:34 Train acc:0.580896686159844 Test acc:0.5702764976958525 Train loss:0.013698258437216282\n",
      "Epoch:35 Train acc:0.5994152046783626 Test acc:0.5806451612903226 Train loss:0.013175169937312603\n",
      "Epoch:36 Train acc:0.5925925925925926 Test acc:0.576036866359447 Train loss:0.013376723974943161\n",
      "Epoch:37 Train acc:0.5838206627680312 Test acc:0.5241935483870968 Train loss:0.013694386929273605\n",
      "Epoch:38 Train acc:0.5745614035087719 Test acc:0.5276497695852534 Train loss:0.013621865771710873\n",
      "Epoch:39 Train acc:0.5969785575048733 Test acc:0.533410138248848 Train loss:0.013083180412650108\n",
      "Epoch:40 Train acc:0.5550682261208577 Test acc:0.5679723502304147 Train loss:0.013837887905538082\n",
      "Epoch:41 Train acc:0.5935672514619883 Test acc:0.565668202764977 Train loss:0.013366015627980232\n",
      "Epoch:42 Train acc:0.5896686159844055 Test acc:0.5633640552995391 Train loss:0.013314439915120602\n",
      "Epoch:43 Train acc:0.5994152046783626 Test acc:0.5794930875576036 Train loss:0.013134430162608624\n",
      "Epoch:44 Train acc:0.5341130604288499 Test acc:0.597926267281106 Train loss:0.014087291434407234\n",
      "Epoch:45 Train acc:0.5492202729044834 Test acc:0.5046082949308756 Train loss:0.013769542798399925\n",
      "Epoch:46 Train acc:0.5277777777777778 Test acc:0.586405529953917 Train loss:0.014107359573245049\n",
      "Epoch:47 Train acc:0.597953216374269 Test acc:0.5921658986175116 Train loss:0.013803829438984394\n",
      "Epoch:48 Train acc:0.6052631578947368 Test acc:0.5645161290322581 Train loss:0.013607800006866455\n",
      "Epoch:49 Train acc:0.5813840155945419 Test acc:0.5990783410138248 Train loss:0.01333179697394371\n",
      "Epoch:50 Train acc:0.5862573099415205 Test acc:0.5829493087557603 Train loss:0.013309641741216183\n",
      "Epoch:51 Train acc:0.6111111111111112 Test acc:0.5737327188940092 Train loss:0.012791370041668415\n",
      "Epoch:52 Train acc:0.6062378167641326 Test acc:0.5599078341013825 Train loss:0.013053925707936287\n",
      "Epoch:53 Train acc:0.594541910331384 Test acc:0.5806451612903226 Train loss:0.012988860718905926\n",
      "Epoch:54 Train acc:0.6081871345029239 Test acc:0.6048387096774194 Train loss:0.012816048227250576\n",
      "Epoch:55 Train acc:0.5974658869395711 Test acc:0.5633640552995391 Train loss:0.012900295667350292\n"
     ]
    }
   ],
   "source": [
    "loops = [True, False]\n",
    "weighted = ['weighted', 'unweighted_dynamic_threshold', 'unweighted_static_threshold']\n",
    "data = ['power_and_entropy', 'only_entropy', 'only_powerbands']\n",
    "\n",
    "lr = 0.001\n",
    "wd = 0.001\n",
    "batch_size = 50\n",
    "hidden_channels = 128 \n",
    "epoches = 1000\n",
    "\n",
    "for loops_config in loops:\n",
    "    for weight_config in weighted:\n",
    "        for dataset in data:\n",
    "            \n",
    "            experiment_name = f'self_loops={loops_config}_weighted={weight_config}_data={dataset}'\n",
    "            \n",
    "            train_dataset = GNNDataset(root = './', \n",
    "                                       data_dict = f'gnn_prepared_data/{dataset}_gnn_train.npy',\n",
    "                                       idx = 0, \n",
    "                                       feature_names = experiment_name, \n",
    "                                       allow_loops = loops_config, \n",
    "                                       weighted = weight_config) # idx = 0 - train\n",
    "            test_dataset = GNNDataset(root = './', \n",
    "                                      data_dict = f'gnn_prepared_data/{dataset}_gnn_test.npy', \n",
    "                                      idx = 1, \n",
    "                                      feature_names = experiment_name,\n",
    "                                      allow_loops = loops_config, \n",
    "                                      weighted = weight_config) # idx = 1 - train\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "            test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "            model = GCN(num_node_features = train_dataset.num_node_features, \n",
    "                        hidden_channels = hidden_channels)\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr = lr, weight_decay = wd)\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "            config = {\n",
    "                        'learning_rate': lr,\n",
    "                        'weight_decay': wd,\n",
    "                        'epochs': epoches,\n",
    "                        'training_batch_size' : batch_size,\n",
    "                        'validation_batch_size' : batch_size,\n",
    "                        'loops_config': loops_config,\n",
    "                        'weight_config': weight_config,\n",
    "                        'dataset': dataset,\n",
    "                        'criterion': criterion,    \n",
    "                        'node_representation_size': train_dataset.num_node_features, \n",
    "                        'model': {\n",
    "                                    'num_graph_conv_blocks': 4,\n",
    "                                    'hidden_channels' : hidden_channels,\n",
    "                                    'activation' : 'ReLU',\n",
    "                                    'readout': 'global_mean_pool'}}\n",
    "\n",
    "            wandb.init(project = 'neuroimaging_gnn_eeg_final_project', \n",
    "                       entity = 'dmasny',\n",
    "                       name = experiment_name, \n",
    "                       config = config)\n",
    "\n",
    "            train(model = model,\n",
    "                  epoches = epoches, \n",
    "                  criterion = criterion, \n",
    "                  train_dataloader = train_loader, \n",
    "                  test_dataloader = test_loader,\n",
    "                  expirement_name = experiment_name)\n",
    "            print(experiment_name)\n",
    "            del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b1039eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mprocessed/\u001b[00m\r\n",
      "├── gnn_dataset_test_all_features.pt\r\n",
      "├── gnn_dataset_train_all_features.pt\r\n",
      "├── pre_filter.pt\r\n",
      "└── pre_transform.pt\r\n",
      "\r\n",
      "0 directories, 4 files\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "!tree processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbeba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = GNNDataset('./', 'gnn_prepared_data/power_and_entropy_gnn_train.npy', \n",
    "#                            0, \n",
    "#                            'all_features',\n",
    "#                            allow_loops = True,\n",
    "#                            weighted = 'weighted')\n",
    "# test_dataset = GNNDataset('./', 'gnn_prepared_data/power_and_entropy_gnn_test.npy', \n",
    "#                           1, \n",
    "#                           'all_features',\n",
    "#                           allow_loops = True,\n",
    "#                           weighted = 'weighted') \n",
    "\n",
    "# model = GCN(num_node_features = train_dataset.num_node_features, \n",
    "#                             hidden_channels = hidden_channels)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr = lr, weight_decay = wd)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "# train(model = model,\n",
    "#       epoches = epoches, \n",
    "#       criterion = criterion, \n",
    "#       train_dataloader = train_loader, \n",
    "#       test_dataloader = test_loader,\n",
    "#       expirement_name = 'debug')\n",
    "\n",
    "# buff = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21bce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9bb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40fe557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
